{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ff5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "import pandas as pd\n",
    "\n",
    "from src.fairface import get_img_name\n",
    "from src.utils import load_json\n",
    "from src.encoder import CLIPEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8649eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucasmc/anaconda3/envs/clipenv/lib/python3.10/site-packages/open_clip/factory.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "backbone = \"ViT-L-14\"\n",
    "datasource = \"laion2b_s32b_b82k\"\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(backbone, pretrained=datasource)\n",
    "model.eval()\n",
    "tokenizer = open_clip.get_tokenizer(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c457e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = load_json(\"../labels/raw_gender_labels.json\")\n",
    "fface = \"/home/lucasmc/Documents/ufrgs/data/datasets/FairFace/\"\n",
    "split = \"val\"\n",
    "fface_csv = f\"{fface}/fface_{split}.csv\"\n",
    "embs_path = f\"{fface}/embeddings/{split}/{backbone}/{datasource}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11004d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val/1.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fface_df = pd.read_csv(fface_csv)\n",
    "files = fface_df[\"file\"]\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d526d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Male': 'a photo of a man', 'Female': 'a photo of a woman'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e43b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucasmc/Documents/ufrgs/clip-face-attribs/src/encoder.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(emb_path)\n"
     ]
    }
   ],
   "source": [
    "labels = list(label_dict)\n",
    "prompts = list(label_dict.values())\n",
    "text = tokenizer(prompts)\n",
    "preds_dict = {\n",
    "    \"file\": [],\n",
    "    \"gender_preds\": []\n",
    "}\n",
    "\n",
    "for file in files:\n",
    "    img_name = get_img_name(file)\n",
    "    image_features = CLIPEncoder.load_embeddings(f\"{embs_path}/{img_name}.npy\")\n",
    "    image_features = image_features.to(device=\"cuda\")\n",
    "    with torch.no_grad(), torch.autocast(\"cuda\"):\n",
    "        text_features = model.encode_text(text).to(device=\"cuda\")\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "    winner = text_probs.argmax()\n",
    "    preds_dict['file'].append(file)\n",
    "    preds_dict['gender_preds'].append(labels[winner])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef375c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d0ac5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "      <th>gender_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val/1.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val/2.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val/3.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val/4.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val/5.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file    age  gender             race  service_test gender_preds\n",
       "0  val/1.jpg    3-9    Male       East Asian         False         Male\n",
       "1  val/2.jpg  50-59  Female       East Asian          True       Female\n",
       "2  val/3.jpg  30-39    Male            White          True         Male\n",
       "3  val/4.jpg  20-29  Female  Latino_Hispanic          True       Female\n",
       "4  val/5.jpg  20-29    Male  Southeast Asian         False         Male"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.merge(fface_df, preds_df, on=\"file\")\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fe44aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>gender_preds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val/1.jpg</th>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/2.jpg</th>\n",
       "      <td>50-59</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/3.jpg</th>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/4.jpg</th>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/5.jpg</th>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/10950.jpg</th>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/10951.jpg</th>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/10952.jpg</th>\n",
       "      <td>60-69</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/10953.jpg</th>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val/10954.jpg</th>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10954 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  gender             race gender_preds\n",
       "file                                                      \n",
       "val/1.jpg        3-9    Male       East Asian         Male\n",
       "val/2.jpg      50-59  Female       East Asian       Female\n",
       "val/3.jpg      30-39    Male            White         Male\n",
       "val/4.jpg      20-29  Female  Latino_Hispanic       Female\n",
       "val/5.jpg      20-29    Male  Southeast Asian         Male\n",
       "...              ...     ...              ...          ...\n",
       "val/10950.jpg  30-39    Male            White         Male\n",
       "val/10951.jpg  50-59    Male            White         Male\n",
       "val/10952.jpg  60-69    Male  Latino_Hispanic         Male\n",
       "val/10953.jpg  20-29  Female       East Asian       Female\n",
       "val/10954.jpg  40-49    Male  Latino_Hispanic         Male\n",
       "\n",
       "[10954 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.set_index('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ed943",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.drop(columns=['service_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cba6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_f = f\"./results/raw_gender_{backbone}_{datasource}_{split}.csv\"\n",
    "result_df.to_csv(out_f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f4513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
